{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9484a7ec",
   "metadata": {},
   "source": [
    "### **dual_ppo**\n",
    "\n",
    "根据论文以及一些建议，考虑使用**dual_ppo**优化算法，在$A<0$时给一个下限$c \\times A$，抑制负优势样本对更新的过度惩罚，当$A \\ge 0$时保持原ppo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55d71c",
   "metadata": {},
   "source": [
    "### **具体代码**\n",
    "\n",
    "\n",
    "在`conf/conf.py`中加入如下的参数控制`dual_ppo`\n",
    "```python\n",
    "USE_DUAL_CLIP_PPO = True\n",
    "DUAL_CLIP_C = 2.0\n",
    "```\n",
    "\n",
    "在`model/model.py`中修改为：\n",
    "```python\n",
    "surr1 = clip_ratio * advantage\n",
    "surr2 = ratio.clamp(1.0 - self.clip_param, 1.0 + self.clip_param) * advantage\n",
    "ppo_objective = torch.minimum(surr1, surr2)\n",
    "if self.use_dual_clip_ppo:\n",
    "    dual_clip_objective = self.dual_clip_c * advantage\n",
    "    surrogate = torch.where(advantage >= 0, ppo_objective,\n",
    "                            torch.maximum(ppo_objective, dual_clip_objective))\n",
    "else:\n",
    "    surrogate = ppo_objective\n",
    "\n",
    "temp_policy_loss = -torch.sum(\n",
    "    surrogate * (weight_list[task_index].float()) * 1\n",
    ") / torch.maximum(torch.sum((weight_list[task_index].float()) * 1), torch.tensor(1.0))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
