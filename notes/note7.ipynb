{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4979f506",
   "metadata": {},
   "source": [
    "### **奖励设计**\n",
    "\n",
    "\n",
    "核心文件位于`feature/reward_process.py`中，需要结合特征处理进行设计，否则出现agent无法感知具体奖励的情况。为了更加清晰框架的奖励设计以及其的工作流程，下面首先分析原本框架的具体流程以及其中关键的数据传输。\n",
    "\n",
    "#### **整体结构**\n",
    "\n",
    "训练主循环 -> Agent -> GameRewardManager\n",
    "\n",
    "1. 训练循环拿到环境给的`obervation[i]`，其中包含：\n",
    "    - `frame_state`：本帧的完整状态\n",
    "2. Agent调用：\n",
    "```python\n",
    "reward = agent.reward_manager.result(observation[i][\"frame_state\"])\n",
    "```\n",
    "\n",
    "3. `result()`返回本步奖励字典(每个子项 + 合计)，供PPO算法记于学习\n",
    "\n",
    "#### **数据流**\n",
    "\n",
    "1. **输入数据结构**：输入环境的`frame_states`\n",
    "\n",
    "2. **输出数据结构**：`result()`的返回值\n",
    "```python\n",
    "{\n",
    "  \"forward\": float,\n",
    "  \"tower_hp_point\": float,\n",
    "  \"hero_hp_point\": float,\n",
    "  \"gold_point\": float,\n",
    "  \"minion_push_depth\": float,\n",
    "  \"kill_event\": float,\n",
    "  \"death_event\": float,\n",
    "  \"tower_danger\": float,\n",
    "  \"dive_no_minion\": float,\n",
    "  \"grass_engage\": float,\n",
    "   # 汇总分：按 GameConfig.REWARD_WEIGHT_DICT 做线性加权求和\n",
    "  \"reward_sum\": float\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### **关键类**\n",
    "\n",
    "`GameRewardManager` \\\n",
    "该类把每一帧的`frame_state`转成本步可以学习奖励字典\n",
    "\n",
    "**关键成员**\n",
    "\n",
    "- `m_main_calc_frame_map: dict[str, RewardStruct]` \\\n",
    "当前“己方阵营”视角的各奖励条目“帧值缓存”（含上一帧值与当前帧值）。\n",
    "- `m_enemy_calc_frame_map: dict[str, RewardStruct]` \\\n",
    "敌方阵营视角的同构缓存\n",
    "- `ABS_NAMES: set[str]` \\\n",
    "指明哪些条目在`get_reward`时按非零和/非差分使用\n",
    "- `EVENT_NAMES: set[str]` \\\n",
    "指明哪些条目按当帧敌我差使用\n",
    "- `TIME_SCALE_ARG: int`\n",
    "时间衰减超参\n",
    "\n",
    "`RewardStruct` \\\n",
    "保存每个条目在“本阵营视角”的上一帧值与当前帧值，方便在后序的奖励计算中进行帧间差分\n",
    "\n",
    "**关键字段**\n",
    "\n",
    "```python\n",
    "class RewardStruct:\n",
    "    last_frame_value: float  # t-1 帧的度量\n",
    "    cur_frame_value:  float  # t 帧的度量\n",
    "```\n",
    "\n",
    "#### **关键函数**\n",
    "\n",
    "`result(frame_state) -> dict`\n",
    "\n",
    "入口调用函数，整合调用顺序：\n",
    "1. `frame_data_process(frame_state)`\n",
    "- 用于产出/更新`m_main_calc_frame_map`、`m_enemy_calc_frame_map`中每个条目的`last_frame_value/cur_frame_value`\n",
    "\n",
    "2. `get_reward(m_main_calc_frame_map, m_enemy_calc_frame_map, frame_state)`\n",
    "- 把帧信息变成每一步奖励：\n",
    "  - 对`ABS_NAMES`：直接用我方`cur_frame_value`\n",
    "  - 对`EVENT_NAMES`：用（我方当帧 − 敌方当帧）\n",
    "  - 对其他条目：用双方差的帧间差分：\n",
    "  `[(我方_cur - 敌方_cur) - (我方_last - 敌方_last)]`\n",
    "  - 若启用时间衰减：乘`0.6 ** (frameNo / TIME_SCALE_ARG)`\n",
    "  - 按权重表`GameConfig.REWARD_WEIGHT_DICT`做线性加权，得到`reward_sum`\n",
    "\n",
    "3. 返回奖励字典\n",
    "\n",
    "---\n",
    "\n",
    "`frame_data_process(frame_state)`\n",
    "\n",
    "把一帧输入拆成己方视角/敌方视角的帧度量缓存：\n",
    "1. 识别阵营\n",
    "  - 从`frame_state.hero_states`找出敌方/己方英雄\n",
    "2. 刷新两套缓存\n",
    "  - 调用`set_cur_calc_frame_vec(self.m_main_calc_frame_map, frame_state, main_camp)`\n",
    "  使得每个条目的`cur_frame_value`和`last_frame_value`计算\n",
    "  - 同样针对敌方的情况进行一致的流程\n",
    "3. 完成后两套Map已经更新完成，送入`get_reward`\n",
    "\n",
    "核心数据：`self.m_main_calc_frame_map`和`self.m_enemy_calc_frame_map`\n",
    "\n",
    "---\n",
    "\n",
    "`set_cur_calc_frame_vec(cul_calc_frame_map, frame_data, camp)`\n",
    "\n",
    "一个阵营的帧值填充器\n",
    "- 输入：\n",
    "  - `cul_calc_frame_map: dict[str, RewardStruct]`将会刷新的一套条目表\n",
    "  - `frame_data: dict`重要的`frame_state`\n",
    "  - `camp: str`该视角的阵营，注意阵营形式为`PLAYERCAMP_2/PLAYERCAMP_1`\n",
    "\n",
    "- 流程：\n",
    "  - 针对每个条目，将旧的`cur_frame_value`转移到`last_frame_value`\n",
    "  - 计算并写入`cur_frame_value`\n",
    "\n",
    "- 输出：\n",
    "  - 最终完成对`self.m_main_calc_frame_map`和`self.m_enemy_calc_frame_map`的更新\n",
    "\n",
    "---\n",
    "\n",
    "`get_reward(main_map, enemy_map, frame_state) -> dict`\n",
    "\n",
    "策略整合器\n",
    "\n",
    "- 按条目组(`ABS_NAMES、EVENT_NAMES`)选择不同的规则，将帧度量组合成本步最终奖励\n",
    "  - ABS：直接用`main_map[name].cur_frame_value`\n",
    "  - 事件：`main_cur - enmey_cur`\n",
    "  - 普通密集量(零和 + 差分)：`(main_cur - enemy_cur) - (main_last - enemy_last)`\n",
    "- 可选时间衰减\n",
    "- 加权汇总\n",
    "- 返回每个条目本步奖励 + reward_sum字典\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f177c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面是整体流程的伪代码\n",
    "class GameRewardManager:\n",
    "    def __init__(self, config):\n",
    "        self.m_main_calc_frame_map = {name: RewardStruct() for name in ALL_NAMES}\n",
    "        self.m_enemy_calc_frame_map = {name: RewardStruct() for name in ALL_NAMES}\n",
    "        self.ABS_NAMES = {...}\n",
    "        self.EVENT_NAMES = {...}\n",
    "        self.TIME_SCALE_ARG = config.TIME_SCALE_ARG\n",
    "        self.weights = GameConfig.REWARD_WEIGHT_DICT\n",
    "\n",
    "    def result(self, frame_state) -> dict:\n",
    "        # 1) 用两套视角把“本帧度量”准备好\n",
    "        self.frame_data_process(frame_state)\n",
    "\n",
    "        # 2) 把“帧度量”转换为“本步奖励”，并做加权\n",
    "        reward_dict = self.get_reward(self.m_main_calc_frame_map,\n",
    "                                      self.m_enemy_calc_frame_map,\n",
    "                                      frame_state)\n",
    "        return reward_dict\n",
    "\n",
    "    def frame_data_process(self, frame_state):\n",
    "        main_camp, enemy_camp = identify_camps(frame_state)\n",
    "        self.set_cur_calc_frame_vec(self.m_main_calc_frame_map, frame_state, main_camp)\n",
    "        self.set_cur_calc_frame_vec(self.m_enemy_calc_frame_map, frame_state, enemy_camp)\n",
    "\n",
    "    def set_cur_calc_frame_vec(self, cul_calc_frame_map, frame_state, camp):\n",
    "        for name, st in cul_calc_frame_map.items():\n",
    "            st.last_frame_value = st.cur_frame_value\n",
    "            st.cur_frame_value  = compute_frame_metric_for(name, frame_state, camp)  # 只填“帧值”\n",
    "\n",
    "    def get_reward(self, main_map, enemy_map, frame_state) -> dict:\n",
    "        per_name = {}\n",
    "        for name in ALL_NAMES:\n",
    "            if name in self.ABS_NAMES:\n",
    "                value = main_map[name].cur_frame_value\n",
    "            elif name in self.EVENT_NAMES:\n",
    "                value = main_map[name].cur_frame_value - enemy_map[name].cur_frame_value\n",
    "            else:\n",
    "                value = ((main_map[name].cur_frame_value - enemy_map[name].cur_frame_value)\n",
    "                        -(main_map[name].last_frame_value - enemy_map[name].last_frame_value))\n",
    "\n",
    "            if self.TIME_SCALE_ARG > 0:\n",
    "                t = frame_state.get(\"frameNo\", 0)\n",
    "                value *= 0.6 ** (t / self.TIME_SCALE_ARG)\n",
    "\n",
    "            per_name[name] = value\n",
    "\n",
    "        reward_sum = sum(self.weights.get(n, 0.0) * v for n, v in per_name.items())\n",
    "        per_name[\"reward_sum\"] = reward_sum\n",
    "        return per_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf42d93",
   "metadata": {},
   "source": [
    "#### **关于阵营信息**\n",
    "\n",
    "代码中存在部分阵营信息提取不太理想/相对繁琐的问题，下面有一个比较好的阵营信息的提取方式，具体如下：\n",
    "```python\n",
    "for hero in frame_data[\"hero_states\"]:\n",
    "    if hero[\"player_id\"] == self.main_hero_player_id:\n",
    "        main_camp = hero[\"actor_state\"][\"camp\"]\n",
    "        self.main_hero_camp = main_camp\n",
    "    else:\n",
    "        enemy_camp = hero[\"actor_state\"][\"camp\"]\n",
    "```\n",
    "\n",
    "注意提取得到的`main_camp`和`enemy_camp`均为`PLAYERCAMP_1/PLAYERCAMP_2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e8998",
   "metadata": {},
   "source": [
    "### **当前设计设计-版本1**\n",
    "\n",
    "\n",
    "注意这里`1 step = 6 frame`，按照逐帧取值，算法侧每步(6帧)再聚合\n",
    "\n",
    "\n",
    "#### **`forward`前进奖励**\n",
    "\n",
    "`forward`前进奖励为非零和的连续值，只针对当前帧的情况计算即可\n",
    "\n",
    "1. 取出三点坐标：`main_tower_pos`，`enemy_tower_pos`，`hero_pos`\n",
    "\n",
    "2. 计算几个距离`dist_hero2emy = dist(hero, enemy_tower)`，`dist_main2emy = dist(main_tower, enemy_tower)`\n",
    "\n",
    "3. 奖励为比值`base`，并且远离时不给奖励(同时这里约束了一个下届$base \\ge 0$)\n",
    "\n",
    "4. 最后将`baes`乘上归一化的血量得到最终的前进奖励\n",
    "\n",
    "具体计算函数：\n",
    "```python\n",
    "def calculate_forward(self, main_hero, main_tower, enemy_tower):\n",
    "    main_tower_pos = (main_tower[\"location\"][\"x\"], main_tower[\"location\"][\"z\"])\n",
    "    enemy_tower_pos = (enemy_tower[\"location\"][\"x\"], enemy_tower[\"location\"][\"z\"])\n",
    "    hero_pos = (\n",
    "        main_hero[\"actor_state\"][\"location\"][\"x\"],\n",
    "        main_hero[\"actor_state\"][\"location\"][\"z\"],\n",
    "    )\n",
    "    forward_value = 0\n",
    "    dist_hero2emy = math.dist(hero_pos, enemy_tower_pos)\n",
    "    dist_main2emy = max(math.dist(main_tower_pos, enemy_tower_pos), 1e-6)\n",
    "    base = (dist_main2emy - dist_hero2emy) / dist_main2emy\n",
    "    base = max(0.0, base)  # 远离敌塔不奖励\n",
    "    hp = float(main_hero[\"actor_state\"][\"hp\"])\n",
    "    mx = max(float(main_hero[\"actor_state\"][\"max_hp\"]), 1.0)\n",
    "    hp_scale = hp / mx\n",
    "    return base * hp_scale  # 或者直接 return base\n",
    "```\n",
    "\n",
    "#### **`tower_hp_point`塔血比例**\n",
    "\n",
    "塔血比例需要同时计算己方和敌方的血量，所以为零和项\n",
    "\n",
    "\n",
    "使用辅助函数得到塔血量比例，\n",
    "```python\n",
    "def _hp_ratio(u):\n",
    "    if not isinstance(u, dict):\n",
    "        return 0.0\n",
    "    hp = float(u.get(\"hp\", 0.0))\n",
    "    mx = float(u.get(\"max_hp\", 0.0))\n",
    "    return hp / mx if mx > 0 else 0.0\n",
    "\n",
    "hero_hp_ratio = _hp_ratio((main_hero or {}).get(\"actor_state\") or {})\n",
    "my_tower_hp_ratio = _hp_ratio(main_tower)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
